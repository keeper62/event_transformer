base_config:
    device: "cpu"

    # Model Hyperparameters
    model:
        vocab_size: 1824
        embed_dim: 512
        num_heads: 8
        num_layers: 6
        ffn_dim: 2048
        num_windows: 30  # Sliding window size for multi-head attention
        max_len: 512
        context_length: 10  # The # steps in the past as input
        prediction_steps: 1  # The # steps in the future to predict
        num_groups: 8
        dropout: 0.1

    # Training Parameters
    training:
        num_epochs: 2
        batch_size: 10

    # Positional Encoding (Defined in event_transformer/models/position.py)
    rpe:
        rpe_class: "LearnableRelativePosition" # Either False or String
    ape:
        ape_class: "LearnableAbsolutePosition" # Either False or String

    # Encoder Settings (Defined in event_transformer/models/decoder.py)
    decoder:
        decoder_class: "CollaborativeAttention"  # Specify decoder class

    # Dataset Settings
    dataset:
        name: "BGL"
        path: "data/BGL.log"
        class: "bgl_dataset" # Make sure to use the correct file name for your dataset without .py extension
        drain_path: "drain3_state.bin"
        columns: 
            - "Label"
            - "Timestamp"
            - "Date"
            - "Node"
            - "Time"
            - "NodeRepeat"
            - "Type"
            - "Component"
            - "Level"
            - "Content"
